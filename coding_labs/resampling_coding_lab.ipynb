{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8368150",
   "metadata": {},
   "source": [
    "# Lab: Cross-Validation\n",
    "\n",
    "This also includes a cross validation method for classification problems, but we'll get to that another time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e004312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                        summarize,\n",
    "                        poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "    (cross_validate,\n",
    "    KFold,\n",
    "    ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d6d9d",
   "metadata": {},
   "source": [
    "# The Validation Set Approach\n",
    "\n",
    "We explore the use of the validation set approach in order to estimate the test error rates that result from fitting various linear models on the `Auto` data set.\n",
    "\n",
    "We use the function `train_test_split()` to split the data into training and validation sets. As there are 392 observations, we split into two equal sets of size 196 using the argument `test_size=196`. It's generally a good idea to set a random seed when performing operations like this that contain an element of randomness, so that the results obtained can be reproduced precisely at a later time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449537ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data(\"Auto\")\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134bfee",
   "metadata": {},
   "source": [
    "Now we can fit a linear regression using only the observations corresponding to the training set `Auto_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac56079",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS([\"horsepower\"])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train[\"mpg\"]\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f4be63",
   "metadata": {},
   "source": [
    "We now use the `predict()` method of the `results` evaluated on the model matrix for this model created using the validation data set. We also calculate the validation MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6103741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(23.616617069669893)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid[\"mpg\"]\n",
    "valid_pred = results.predict(x_valid)\n",
    "np.mean((y_valid - valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d277f89c",
   "metadata": {},
   "source": [
    "Hence our estimate for the validation MSE of the linear regression fit is 23.62.\n",
    "\n",
    "We can also estimate the validation error for higher-degree polynomial regressions. We first provide a function `evalMSE()` that takes a model string as well as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35973df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "    \n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "\n",
    "    return np.mean((y_test - test_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99499667",
   "metadata": {},
   "source": [
    "Let's use this function to estimate the validation MSE using linear quadratic and cubic fits. We use the `enumerate()` function here, which gives both the values and indices of objects as one iterates over a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39363863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly(\"horsepower\", degree)],\n",
    "                       \"mpg\",\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "    \n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94a6df",
   "metadata": {},
   "source": [
    "These error rates are 23.62, 18.76, and 18,80, respectively. If we choose a different training/validation split instead, then we can expect somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b70c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly(\"horsepower\", degree)],\n",
    "                       \"mpg\",\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "    \n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0690db2",
   "metadata": {},
   "source": [
    "Using this split of the observations into a training set and a validation set, we find that the validation set error rates for the models start with linear, quadratic, and cubic terms are 20.76, 16.95, and 16.97, respectively.\n",
    "\n",
    "These results are consistent with our previous findings: a model that predicts `mpg` using a quadratic function of `horsepower` performs better than a model that involves only a linear function of `horsepower`, and there's no evidence of improvement in using a cubic function of `horsepower`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin-reg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
